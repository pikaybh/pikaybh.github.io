---
title:  "Harnessing Generative Pre-Trained Transformers for Construction Accident Prediction with Saliency Visualization"
excerpt: "**Byunghee Yoo**, **Jinwoo Kim**, **Seongeun Park**, **Changbum R. Ahn**, & **Taekeun Oh** (Jan 12th, 2024)"
classes: wide
author_profile: false
sidebar:
  - image: https://iconape.com/wp-content/png_logo_vector/mdpi-multidisciplinary-digital-publishing-institu-logo.png
    href: https://doi.org/10.3390/app14020664
    image_alt: "logo"
  - title: "<a href='#' style='color: #3d4144; text-decoration: none'>Table of Contents</a>"
    text: "<a href='#abstract' style='color: #3d4144; text-decoration: none'>Abstract</a><br/><a href='#1-introduction' style='color: #3d4144; text-decoration: none'>1. Introduction</a><br/><a href='#2-research-background' style='color: #3d4144; text-decoration: none'>2. Research Background</a><br/><a href='#3-materials-and-methods' style='color: #3d4144; text-decoration: none'>3. Materials and Methods</a><br/><a href='#4-results' style='color: #3d4144; text-decoration: none'>4. Results</a><br/><a href='#5-discussion' style='color: #3d4144; text-decoration: none'>5. Discussion</a><br/><a href='#6-conclusion' style='color: #3d4144; text-decoration: none'>6. Conclusions</a><br/><a href='#references' style='color: #3d4144; text-decoration: none'>References</a>"
  - title: "Citation"
    text: "<p id='citation'>Yoo, B.; Kim, J.; Park, S.; Ahn, C.R.; Oh, T. Harnessing Generative Pre-Trained Transformers for Construction Accident Prediction with Saliency Visualization. <i>Appl. Sci.</i> <b>2024</b>, <i>14</i>, 664. <a href='https://doi.org/10.3390/app14020664' style='color: #3d4144' target='_blank'>https://doi.org/10.3390/app14020664</a></p>"
  - title: "Copyright"
    text: "© 2024 by the authors. Licensee MDPI, Basel, Switzerland."
---

| by **Byunghee Yoo**<sup>1</sup>, **Jinwoo Kim**<sup>2</sup>, **Seongeun Park**<sup>1</sup>, **Changbum R. Ahn**<sup>1, *</sup>, and **Taekeun Oh**<sup>3, *</sup><br/><br/><sup>1</sup> Department of Architecture and Architectural Engineering, Seoul National University, Gwanak-gu, Seoul 08826, Republic of Korea<br/><sup>2</sup> Department of Architectural Engineering, Gachon University, Seongnam-si 13120, Gyeonggi-do, Republic of Korea<br/><sup>3</sup> Department of Safety Engineering, Incheon National University, Incheon 22012, Republic of Korea<br/><sup>\*</sup> Authors to whom correspondence should be addressed.

# Abstract

Leveraging natural language processing models using a large volume of text data in the construction safety domain offers a unique opportunity to improve understanding of safety accidents and the ability to learn from them. However, little effort has been made to date in regard to utilizing large language models for the prediction of accident types that can help to prevent and manage potential accidents. This research aims to develop a model for predicting the six types of accidents (caught-in-between, cuts, falls, struck-by, trips, and others) by employing transfer learning with a fine-tuned generative pre-trained transformer (GPT). Additionally, to enhance the interpretability of the fine-tuned GPT model, a method for saliency visualization of input text was developed to identify words that significantly impact prediction results. The models were evaluated using a comprehensive dataset comprising 15,000 actual accident records. The results indicate that the suggested model for detecting the six accident types achieves 82% accuracy. Furthermore, it was observed that the proposed saliency visualization method can identify accident precursors from unstructured free-text data of construction accident reports. These results highlight the advancement of the generalization performance of large language processing-based accident prediction models, thereby proactively preventing construction accidents.

# 1. Introduction

An unprecedented volume of digital data, approximately 330 million terabytes daily, is now available <sub>[<a href="#ref1">1</a>]</sub>. Looking ahead to the next two years leading up to 2025, the global production of data is projected to soar beyond 181 zettabytes [2]. A significant portion of this data exists in unstructured forms, encompassing text, images, and videos, making up an estimated 80% of the total [3]. This surge in data presents the challenge of information overload, where the sheer volume surpasses the capabilities for effective processing and analysis [4]. This issue is particularly pronounced for unstructured free-text data, which traditionally relies on human intervention to extract meaningful insights [5]. Therefore, the development of automated techniques for processing natural language text is becoming increasingly vital.

The construction sector is also witnessing a data surge and an increasing emphasis on leveraging written text, particularly within the domain of construction safety through digital accident reports [6,7]. The ability to learn from past accidents, incidents, and near misses holds paramount importance in preventing future injuries [6,8,9,10]. Safety reports, in particular, serve as invaluable resources for safety managers, providing insights into the conditions and events that lead to accidents. This information is crucial for implementing interventions and ensuring positive safety outcomes. Traditionally, all construction-related disasters, including accidents, incidents, and near-misses, have been documented in safety reports using unstructured or semi-structured free-text formats. These reports encompass event descriptions, timing information, and location details [11,12]. However, analyzing accident report data is often laborious and time-consuming, demanding profound understanding of safety to extract meaningful insights [11,13]. The conventional approach involves the manual classification of accident cases, typically undertaken by safety professionals [11,14]. This method requires a meticulous review of detailed textual accident reports to categorize accidents based on various accident-related attributes. Furthermore, beyond consuming substantial resources, manual classification is susceptible to human bias and errors, potentially leading to incomplete or inaccurate analyses.
The advancements in artificial intelligence (AI) now allow for the automated processing, organization, and handling of free-text data, streamlining this analytical process [15]. Specifically, text rule-based, machine, and deep learning approaches have been showing potential in predicting anticipated danger and enhancing the understanding of accident causation. For instance, Zhang et al. [16] developed models aimed at classifying 11 causes of accidents, such as instances of being caught-in-between objects, the collapse of objects, electrocution, exposure to chemical substances, among others, utilizing accident report data and machine learning algorithms. The results of their study demonstrated the average F1 score for 11 causes of accidents was 0.68, showcasing the effectiveness of their proposed ensemble model with optimized weights. Separately, Baker et al. [17] developed machine learning models (e.g., random forest, extreme gradient boosting, and linear support vector machine) to predict four safety outcomes, such as injury severity, injury type, the body part impacted, and accident type. The results showed 84.84% in F1 scores for severity prediction. These studies underscore the significance of leveraging advanced modeling techniques to gain insights into the diverse factors contributing to accidents and improve safety measures. Nevertheless, previous research in this domain has primarily concentrated on the development of traditional machine and deep learning methods. These methods involve the manual extraction of text features, which are subsequently fed into a classifier [11]. These approaches contain several inherent limitations such as limited scalability/generalization, difficulty in analyzing free-from text, high dimensionality, and limited adaptability to new tasks. Although traditional machine/deep learning-based approaches have made significant strides in the natural language processing (NLP) of the construction domain, such limitations must be mitigated by incorporating more generative and powerful AI models [18].

Recently, large language models (LLMs), particularly those built on the transformer architecture, such as the generative pre-trained transformer (GPT), present notable advantages for classification tasks compared to traditional machine learning and deep learning models [19,20]. The transformer’s ability to capture contextual information, employ end-to-end learning without manual feature engineering, utilize attention mechanisms for distinct understanding, and leverage transfer learning for improved performance make it well-suited for tasks that require a comprehension of accident-related text data [21]. Additionally, its adaptability to varied input lengths, multimodal capabilities, and efficient parallelization contribute to its efficacy in handling the complexities of accident classification, marking a significant advancement over more traditional approaches in the field [22]. Despite these potential benefits of LLM, leveraging GPT models is still an explanatory stage in the construction accident domain. Further research and validation are needed to assess the model’s performance, generalizability across diverse accident scenarios, and its interpretability in the context of safety-critical applications. Additionally, addressing domain-specific challenges and tailoring the model to the unique characteristics of construction-related text data via the fine-tuning method is crucial for maximizing the effectiveness of GPT-based approaches in accident classification within the construction industry.
In this regard, the authors developed a model to predict construction accidents and visualize accident precursors using a fine-tuned GPT model from raw construction accident reports. The contributions of this paper are as follows: (1) The authors developed an approach to automatically classify construction accidents from a dataset of raw construction accident reports using a fine-tuned GPT with various hyperparameter optimizations (e.g., max token and temperature parameters). Such information holds unique value, as it can enhance the ability to understand, predict, and prevent accidents; (2) This paper proposes a method to identify word patterns that, following the fine-tuning process, consistently demonstrate high predictiveness for each safety outcome; (3) The suggested methods can also serve to visualize and comprehend the models’ prediction sensitivity; and (4) The authors experimented with four state-of-the-art machine learning [Term Frequency-Inverse Document Frequency (TF-IDF)], deep learning [Convolutional Neural Network (CNN)], and two LLMs [fine-tuned GPT 2.0/3.0 and Korean Bidirectional Encoder Representations from Transformers (BERT)] using structured and unstructured text from construction accident reports.

This paper is structured as follows to demonstrate the aforementioned contributions. First, the authors offer a background regarding the utilization of machine learning, deep learning, and LLMs in NLP in Section 2. Subsequently, in Section 3, the authors outline the structure of the proposed model, introducing the saliency visualization of accident attributes in unstructured free-text data. In Section 4, the authors test the developed method with the actual construction accident dataset and the preprocessing procedures applied and elaborate on the experimental configuration alongside comparative benchmark models, and report the results. Then, Section 5 includes a comprehensive analysis and interpretation of the findings. Lastly, Section 6 provides a summary and conclusion of the study’s key contributions. The findings of this paper underscore the improved generalization performance of construction accident prediction models based on large language processing, leading to a proactive approach in preventing accidents at construction sites.

# 2. Research Background

The adoption of NLP analysis presents a transformative shift in the realm of construction site safety [23]. NLP, equipped with its ability to sift through extensive textual data, provides a robust framework for uncovering subtle patterns and correlations within accident records [24,25]. This enables stakeholders to access distinctive insights into the fundamental reasons behind accidents, enabling the creation of proactive and specific safety measures to avert the recurrence of similar incidents [26,27]. By leveraging the capabilities of NLP, construction site managers and safety experts can optimize their decision-making processes, bolstering the efficacy of accident analysis and fortifying the overall safety standards within the construction industry [28]. This transition to NLP-driven analysis signifies a progressive stride toward a more data-driven and proactive approach to accident prevention, ultimately fostering a safer working environment for construction personnel and mitigating potential risks associated with complex construction operations.

Specifically, recent developments in NLP have created novel opportunities for the automated examination of textual records related to accidents [17,23,29,30]. By applying NLP techniques, pertinent information can be extracted from unstructured free-text data, enabling an effective categorization of accidents based on various parameters [31]. Numerous studies have emphasized the efficacy of NLP in automating accident classification, resulting in improved efficiency and reduced prejudice. Table 1 presents a summary of the NLP models used in the literature to predict construction accidents. Specifically, Tixier et al. [32] demonstrated analyzing unstructured incident reports utilizing the NLP model, yielding significant results with F1 score values of 0.96, respectively. Similarly, Zhang et al. [16] employed text mining and NLP methods to investigate construction accident reports, utilizing various machine learning models, with the optimized ensemble model showcasing the highest F1 score of 0.68. Cheng et al. [33] introduced the Symbiotic Gated Recurrent Unit for the classification of construction site accidents, achieving an average weighted F1 score of 0.69, outperforming other AI techniques. Additionally, Kim & Chi [34] developed a system for managing construction accident knowledge, demonstrating notable recall, precision, and F1 score values of 0.71, 0.93, and 0.80, respectively.

**Table 1.** Natural Language Processing and Construction Injury Classification Literature.

| Authors (Year) | Task | Source Data | Text Fields | Outperformed Method | Accuracy |
| :--: | :--: | :--: | :--: | :--: | :--: |
| Tixierc, A.J.P., et al. (2020) [6] | Prediction of 6 incident type, 4 injury type, 6 body part, 2 severity from injury reports | A dataset of 90,000 incident reports from global oil refineries | Title, accident details, detail, root cause | TF-IDF + SVM | 71.55% |
| Kim, H., Jang, Y., Kang, H. & Yi, J.S. (2022) [35] | Classification of 5 accident case from accident reports	Korea Occupational Safety and Health Agency | Accident case | CNN | 52% |
| Zhang, Jinyue, et al. (2020) [14] | Classification of 11 accident categories from accident reports | Occupational Safety and Health Administration | Accident narratives | BERT | 80% |
| Goh, Y.M. & Ubeynarayana, C.U. (2017) [36] | Classification of 11 labels of accident causes or types from accident reports | Occupational Safety and Health Administration | Accident narratives | SVM | 62% |
| Zhang, Fan, et al. (2019) [16] | Classification of 11 causes of accidents from accident reports | Occupational Safety and Health Administration | Fatality and catastrophe investigation summary reports | Ensemble | 68% |
| Cheng, M.Y., Kusoemo, D. & Gosno, R.A. (2020) [33] | Classification of 11 labels of accident causes or types from accident reports | Occupational Safety and Health Administration | Accident narratives | Hybrid model | 69% |

These research efforts emphasize the importance of employing advanced NLP-based modeling techniques to gain a comprehensive understanding of the various factors influencing accidents and to improve safety protocols. However, as mentioned in the Introduction, current studies have predominantly focused on developing conventional machine and deep learning methods, which entail manually extracting text features and inputting them into a classifier [15,29,36]. These approaches come with inherent limitations, including limited scalability and generalization, difficulties in analyzing free-form text, high dimensionality, and a lack of adaptability to new tasks. While traditional machine and deep learning methods have made strides in NLP within the construction domain, overcoming these limitations requires the incorporation of more innovative, generative, and robust AI models.

Recently, LLMs, particularly those built on the transformer architecture such as GPT, developed by OpenAI, present notable advantages for various NLP tasks, including classification, compared to traditional machine learning and deep learning models [20,37]. These models are trained on vast datasets, enabling them to generate human-like text based on the input they receive. The adaptability and proficiency of GPT models in processing and generating natural language have the potential to significantly impact and facilitate various aspects in diverse fields, ranging from education and customer service to research and industries.

The capacity of GPT to generate text resembling human writing can be attributed to its deployment of the transformer model. The transformer model employed in GPT is depicted in Figure 1. The model employs a decoder structure with 96 repeated layers. These layers allow the model to progressively refine its understanding of the input text, enabling it to generate coherent and contextually relevant outputs [38]. The repeated stacking of decoder layers, coupled with attention mechanisms and residual connections, ensures the model’s proficiency in tasks such as language translation and text generation, particularly classification [39,40]. The transformer demonstrates proficiency in capturing contextual information, implementing end-to-end learning without manual feature engineering, employing attention mechanisms for nuanced comprehension, and leveraging transfer learning to improve performance [41]. These qualities make it well-suited for tasks that require an in-depth understanding of unstructured free-text data pertaining to accidents [21]. Additionally, its adaptability to diverse input lengths, multimodal capabilities, and efficient parallelization collectively contribute to its efficacy in tackling the complexities inherent in accident classification [42]. This marks a significant advancement over traditional approaches in the field, reflecting a substantial progress in the capabilities of NLP models. Despite these potential benefits of LLM, there still exists a knowledge gap on how to better utilize pre-trained GPT models through fine- and hyperparameter-tunings with enhancing explainability for construction accident classification. This research is anticipated to contribute to the expanding knowledge base on NLP applications in safety management, providing practical insights for safety professionals, researchers, and policymakers dedicated to enhancing safety practices within the industry.

**Figure 1.** Transformer architecture used in a generative pre-trained transformer (Modified from Radford et al. [20] and Brown et al. [39]).

!["Figure 1. Transformer architecture used in a generative pre-trained transformer (Modified from Radford et al. and Brown et al. ."](https://www.mdpi.com/applsci/applsci-14-00664/article_deploy/html/images/applsci-14-00664-g001.png)

# 3. Materials and Methods

Despite the existence of traditional machine and deep learning-based algorithms to predict causes of accidents from structured and unstructured data, their effective use for accident classification poses technical challenges (e.g., manual feature extraction, limited to scalability/generalization/explainability, difficulty in free-from text, high dimensionality, and limited adaptability to new tasks). In this section, the authors demonstrate an alternative approach that uses GPT models, on an existing construction unstructured and structured text data to classify 6 construction accident types (caught-in-between, cuts, falls, struck-by, trips, and others) and visualize word saliency to better understand the cause of accidents.

## 3.1. Fine-Tuning in Generative Model Using Construction Report Data

In developing a model to predict construction accident types, this paper used a pre-trained GPT 2.0 and 3.0 model with fine-tuning using training data (unstructured free-text data from construction accident reports). The foundation of the GPT model lies in the transformer architecture introduced by Vaswani et al. [21]. The transformer architecture revolutionized NLP by replacing traditional recurrent neural networks with a self-attention mechanism. This mechanism enables GPT to effectively capture long-range dependencies in text data [20].

Figure 2 presents the fine-tuning and generating prediction outcome process. The initial step involves fine-tuning a pre-trained model on the data intended for training. Unlike prompt engineering, this involves exposing the model to the new data and allows it to adjust its internal weights and biases to better generate responses similar to the specific training data. Fine-tuning a GPT model allows for customization to specific tasks or domains, enhancing its performance on specialized inputs. This process enables the model to learn task-specific information and improve its accuracy in generating contextually relevant outputs. This paper used 5400 cases of unstructured free-text data from the construction injury report for the fine-tuning process. The data is not overlapped with the test dataset. After the fine-tuning process, the developers can interact with the fine-tuned model using the application programming interface (API) gateway of OpenAI as shown in Figure 3. For the purpose of training, the preprocessing step involves formatting the training data into JSON files, where the input data and output data are paired as ‘prompt’ and ‘completion’, respectively. These files are then uploaded through the API gateway. Once the fine-tuning process is complete the developers can iteratively utilize the completion generated by the fine-tuned model. For example, the fine-tuned model generates a prediction outcome if one case of text data from a construction accident report is submitted in the playground page. The outcome can be validated with the actual accident outcome. To effectively utilize the API gateway of OpenAI, the authors developed an automated tuning process and generating prediction outcome process using Python.

Figure 2. Overarching fine-tuning process and generating prediction outcome process.

![Figure 2. Overarching fine-tuning process and generating prediction outcome process.](https://www.mdpi.com/applsci/applsci-14-00664/article_deploy/html/images/applsci-14-00664-g002.png)

Figure 3. An example of a visualization platform to interact with a fine-tuned model: (a) a prompt with one case of text data from a construction accident report; (b) a prediction outcome, also known as a completion; (c) a model name; (d) temperature parameter; and (e) maximum length of the prediction outcome (max_tokens parameter). The completion is highlighted in various colors to visually demonstrate how confidently the fine-tuned model responded to each word. The closer to green, the closer the log probability is to 0, and the closer to red, the closer it is to negative infinity. In a small window, the model’s confidence in each token is displayed as a percentage.

![Figure 3. An example of a visualization platform to interact with a fine-tuned model: (a) a prompt with one case of text data from a construction accident report; (b) a prediction outcome, also known as a completion; (c) a model name; (d) temperature parameter; and (e) maximum length of the prediction outcome (max_tokens parameter). The completion is highlighted in various colors to visually demonstrate how confidently the fine-tuned model responded to each word. The closer to green, the closer the log probability is to 0, and the closer to red, the closer it is to negative infinity. In a small window, the model’s confidence in each token is displayed as a percentage.](https://www.mdpi.com/applsci/applsci-14-00664/article_deploy/html/images/applsci-14-00664-g003.png)

Additionally, there are several parameters that need to be considered, and the authors confirmed that two hyperparameters (‘temperature’ and ‘max_tokens’) can influence overall performance on the prediction outcome of GPT models. Specifically, the ‘temperature’ parameter controls randomness in the generated output. Lower values make the completions less random. As the temperature approaches zero, the model becomes more deterministic and tends to produce repetitive output. The authors set the ‘temperature’ to 0.2 based on the results of sensitivity analysis. Separately, the ‘max_tokens’ parameter limits the number of tokens (words or subwords) in the generated text during language generation tasks. Setting a specific value for ‘max_tokens’ limits the length of the generated output, impacting the completeness and context of the response. If set too low, it might result in truncated or incomplete responses, while a high value could lead to overly lengthy and potentially less coherent outputs. Choosing an appropriate ‘max_tokens’ value is crucial to obtaining desired results in terms of length and relevance. Thus, the authors tested the length of ‘max_tokens’ from 4 to 50 and observed that the 10 consistently produces reliable results.

### 3.2. Saliency Visualization of Accident Attributes in Unstructured Free-Text Data

Motivated by the desire to unravel the inner workings of GPT models and address their inherent black-box nature, the authors further developed a model to shed light on the transparent process of output generation. By systematically assessing the impact of individual words within an input sentence on the final output, this paper strives to enhance interpretability and provide users with a clearer understanding of the model’s prediction accuracy. This is accomplished by strategically manipulating the location of words within a sentence, enabling the discernment of their unique contributions to the overall output. Each word is removed from its respective position, and the sentence is reassembled to obtain prediction accuracy. The Importance Score for a specific word in the sentence, denoted as 𝑤𝑖
, is computed as follows:

$$
𝐼𝑚𝑝𝑜𝑟𝑡𝑎𝑛𝑐𝑒 𝑆𝑐𝑜𝑟𝑒𝑖=1−𝑃(𝑆−{𝑤𝑖})𝑃(𝑆)=1−𝑃(𝑤𝑖𝑐|𝑆)𝑤ℎ𝑒𝑟𝑒,  𝑆={𝑤1, 𝑤2, 𝑤3, ⋯, 𝑤𝑛} ... (1)
$$

- 𝑆 represents the set of all word elements contained in the sentence.
- 𝑤 represents an individual word in the set 𝑆, with the subscript indicating the positional information of that word.

In this equation, 𝑃(𝑆−{𝑤𝑖})
 represents the probability of an accident that can occur within the sentence 𝑆
 occurring when the researchers remove or exclude the element, a word, 𝑤𝑖
 from it. 𝑃(𝑆)
 represents the probability of an accident that can occur within the sentence 𝑆
 happening in its entirety. The 𝐼𝑚𝑝𝑜𝑟𝑡𝑎𝑛𝑐𝑒 𝑆𝑐𝑜𝑟𝑒𝑖
 essentially quantifies the significance or importance of the element 𝑤𝑖
 within the context of event 𝑆
. It is calculated as the difference between 1 and the product of two probabilities: one representing the occurrence of 𝑆
 with the element 𝑤𝑖
 removed and the other representing the overall probability of 𝑆
. Ultimately, it can be summarized as 1−𝑃(𝑤𝑖𝑐|𝑆)
 by the properties of the set difference and conditional probability. If log probability is used, then the values should be normalized to a range between 0 and 1 using exponential transformation:

$$
𝐼𝑚𝑝𝑜𝑟𝑡𝑎𝑛𝑐𝑒 𝑆𝑐𝑜𝑟𝑒_𝑖=1−𝑒^{𝑃(𝑆−\{𝑤_𝑖\})−𝑃(𝑆)}
$$

Algorithm 1 illustrates the pseudocode to operate saliency visualization. This methodology allows for a quantitative comparison of the impact of each word on the final output, providing insights into the black-box behavior of the GPT model. Using this methodology, the researchers can obtain a set of Importance Scores for all the words that make up a sentence. Below is the detailed description of Algorithm 1:

Algorithm 1 Computing Importance Scores for words in a sentence
Input: A sentence of text data 𝑆𝑒𝑛𝑡
;
Output: List 𝑆𝑐𝑜𝑟𝑒𝑠
;
1  Split 𝑆𝑒𝑛𝑡
 into a List of words 𝑆
; 𝑆={𝑤1, 𝑤2, 𝑤3, ⋯, 𝑤𝑛}

2  Declare 𝑆𝑐𝑜𝑟𝑒
 variables on the disk; 𝑆𝑐𝑜𝑟𝑒1, 𝑆𝑐𝑜𝑟𝑒2, 𝑆𝑐𝑜𝑟𝑒3, ⋯, 𝑆𝑐𝑜𝑟𝑒𝑛

3  for i from 1 to n do
4    𝑆𝑖=𝑆−{𝑤𝑖}

5   𝑆𝑒𝑛𝑡𝑖=𝐶𝑜𝑛𝑐𝑎𝑡(𝑆𝑖)

6   𝑆𝑐𝑜𝑟𝑒𝑖=1−𝑃(𝑆𝑒𝑛𝑡𝑖)𝑃(𝑆𝑒𝑛𝑡)

7  end for
8  Assign 𝑆𝑐𝑜𝑟𝑒𝑠={𝑆𝑐𝑜𝑟𝑒1, 𝑆𝑐𝑜𝑟𝑒2, 𝑆𝑐𝑜𝑟𝑒3, ⋯, 𝑆𝑐𝑜𝑟𝑒𝑛}

The algorithm commences by performing tokenization on the input sentence, 𝑆𝑒𝑛𝑡
, resulting in the generation of a list of words, denoted as 𝑆
. It subsequently initializes score variables 𝑆𝑐𝑜𝑟𝑒1
 through 𝑆𝑐𝑜𝑟𝑒𝑛
 for each word in the sentence. The algorithm then proceeds to iterate through each word, eliminating the 𝑖
-th word 𝑤𝑖
 from 𝑆
, thereby creating modified sentences 𝑆𝑖
. The scores 𝑆𝑐𝑜𝑟𝑒𝑖
 for each modified sentence 𝑆𝑖
 are calculated using the formula:
𝑆𝑐𝑜𝑟𝑒𝑖=1−𝑃(𝑆𝑖)𝑃(𝑆𝑒𝑛𝑡𝑖),
where 𝑃(𝑆𝑖)
 represents the probability of the modified sentence, and 𝑃(𝑆𝑒𝑛𝑡)
 represents the probability of the original sentence. Finally, the resulting scores 𝑆𝑐𝑜𝑟𝑒1
 through 𝑆𝑐𝑜𝑟𝑒𝑛
 are stored in the 𝑆𝑐𝑜𝑟𝑒𝑠
 list for subsequent analysis and interpretation.
This algorithm provides a systematic approach to assess the impact of individual words within a given sentence. It calculates a score for each word by considering the change in sentence probability when that word is removed. These scores can be valuable for various NLP tasks, such as keyword extraction, text summarization, and sentiment analysis.

# 4. Results

## 4.1. Data

The authors obtained a total of approximately 15,000 construction accident report data in South Korea from 1990s to 2022. The data were categorized into a total of six types: caught-in-between, cut, falls, struck-by, trips, and others. The “others” includes the accident types (e.g., overexertion, occupational diseases, and fire) that cannot be classified in the remaining five accident types and takes small proportions, which can decrease the reliability of the classification results. The selection of the six types of accidents in this study is based on a comprehensive analysis of accident reports, existing literature, industry standards, and common occurrences in construction sites [13,29,43]. These six accident types encompass a broad spectrum of incidents that are frequently reported and have significant implications for construction site safety.

Addressing the issue of data imbalance is indeed a critical task in order to improve the performance of a classification model. Thus, the authors downsampled by randomly selecting 1000 records from each category to resolve imbalanced data issues. Fine-tuning involves transferring learning onto a pre-trained model that has been trained on a large amount of data, and it often performs well even with a limited amount of data. Moreover, transfer learning is adopted as a viable solution to overcome data scarcity issues.

Table 2 shows variables and features from construction accident reports. The report contains two input data: unstructured and structured text data. The structured text data contain contextual information (e.g., date, time, weather, temperature, type of construction) during accident events. The unstructured, free-text, data include narrative details of the accident. Figure 4 presents an example of the unstructured data. It describes the details of accident circumstances. Additionally, the portions in the accident circumstances that directly provided information about the occurrence of accidents or allowed for the direct identification of accident types was removed. For example, the sentence highlighted in red in Figure 4, “As the backhoe was reversing to return, the signalman, who was attempting to guide the backhoe, got entangled in its caterpillar”, directly mentions the word “got entangled” which directly reveals the injury type.

Figure 4. A sample text to illustrate the unstructured data (stop words highlighted in red color).

![Figure 4. A sample text to illustrate the unstructured data (stop words highlighted in red color).](https://www.mdpi.com/applsci/applsci-14-00664/article_deploy/html/images/applsci-14-00664-g004.png)

Table 2. Variables and features from construction accident reports.

//표//

## 4.2. Baseline Models

To evaluate the performance of the developed 2.0 and 3.0 fine-tuned GPT-based method, this study selected three base classifiers, namely TF-IDF, CNN, and BERT, for comparison based on the literature [6,11,14]. The baseline models play an important role in classification research as they provide essential benchmarks for evaluating the performance of more complex or new models. By implementing existing algorithms or traditional AI approaches, baseline models set a standard against which the effectiveness of novel methods can be measured. The baseline models serve as reference points for assessing improvements and offer insights into the challenges of a specific task. The model’s performance underwent assessment through a designated test set. To ensure robust evaluation, distinct training and testing splits were formulated for outcome categories. 90% of the reports were allocated for training purposes, while the remaining 10% were reserved for testing the model’s predictive capabilities [44,45]. Additionally, for the optimization of parameters in the GPT model, a validation set was meticulously generated for each outcome. This involved randomly isolating 10% of the training set, providing a dedicated dataset for fine-tuning and enhancing the model’s precision in predicting specific accident types. This allocation, termed a validation set, plays a crucial role in refining model performance by facilitating hyperparameter tuning and mitigating overfitting risks [46,47].

1. TF-IDF, is a statistical measure that indicates how important a word is within a specific document in a collection of documents [48]. Typically used in information retrieval and text mining [49], TF-IDF provides weightings but does not involve learning on its own. However, it can be integrated with machine learning techniques and has surprisingly demonstrated strong performance in prior research, earning its selection as a benchmark model. Both the stochastic gradient descent (SGD) classifier and support vector machine (SVM) classifier were trained using the weights obtained from the TF-IDF vectorizer, and their accuracy was measured. In the training of the SGD classifier, the performance of four different kernels (radial basis function, linear, poly, sigmoid) was compared. Among these, the Linear Kernel yielded the highest accuracy. In the training of the SVM classifier, nine different loss parameters (logistic, hinge, modified huber, squared hinge, perceptron, squared error, huber, insensitive, squared epsilon insensitive) were utilized. Among these, the logistic loss parameter resulted in the highest accuracy.
2. CNN specializes in deep learning models for image and grid data processing [50,51]. They use convolutional layers to detect features, pooling layers to downsample, and fully connected layers for classification. CNNs excel in tasks such as image recognition and have wide applications in computer vision and beyond. In the dataset, the following parameters yielded the most optimal results. The number of epochs was set to 8, following experimentation in the range of 6 to 100, while the batch size was configured to 64, tested across a range from 32 to 128. An embedding dimension of 300 was used, accompanied by 100 filters and filter sizes of 2, 3, and 4. A dropout rate of 0.5 was applied during training. The optimizer employed was Adam, and the criterion was defined as CrossEntropyLoss, since the task is multiclass classification. The text was tokenized using the spacy.load (“ko_core_news_sm”) tokenizer supported by spacy, which is the Python library. The pre-trained model used for the tokenizer is “ko_core_news_sm”. These parameters were crucial in achieving the desired outcomes, as highlighted in the provided data.
3. BERT is indeed a type of LLM, similar to GPT, but it’s a smaller model with only 0.3 billion parameters compared to GPT-3.0’s 175 billion parameters [39,52]. The number of parameters in LLMs is proportional to the size of the training dataset. To investigate whether there is a performance difference in the dataset based on the number of parameters, experiments were conducted using BERT. The experiments were conducted using Python and the Keras TensorFlow package [52,53]. The training of the BERT model was based on the BERT-Base model available from Google on GitHub. The BERT-Base model supports 104 languages and consists of 12 layers, 768 hidden units per layer, 12 attention heads, and 110 million parameters. For optimization, the RAdam optimizer was chosen, incorporating a weight decay of 0.0025 [54,55]. Since the task involves multi-class classification, the sparse categorical cross-entropy loss function was employed. Furthermore, the following parameters that produced the best performance were used in this paper: sequence length (128), batch size (16), epochs (8), learning rate (0.00001), optimizer (Adam).

## 4.3. Experiment Results

The results of the baseline models (TF-IDF, CNN, BERT) and fine-tuned GPT 2.0/3.0 models can be seen in Table 3. Each column presents the results for a specific outcome category, and the last column represents the average value across all categories. Identical performance metrics were applied to all models, encompassing precision, recall, F1 score, and accuracy. Precision measures the ratio of correctly identified positive instances to all instances classified as positive by the classifier, while Recall quantifies the ratio of correctly identified positive instances to the total number of relevant samples (i.e., all instances that should have been correctly identified as positive) [56,57]. The F1 score can be considered as a comprehensive assessment metric that amalgamates Precision and Recall [58].

---

# References

1. <p id="ref1">Rydning, D.R.-J.G.-J.; Reinsel, J.; Gantz, J. The digitization of the world from edge to core. <i>Fram. Int. Data Corp</i>. <b>2018</b>, <i>16</i>, 1–28. [<a href="https://scholar.google.com/scholar_lookup?title=The+digitization+of+the+world+from+edge+to+core&author=Rydning,+D.R.-J.G.-J.&author=Reinsel,+J.&author=Gantz,+J.&publication_year=2018&journal=Fram.+Int.+Data+Corp.&volume=16&pages=1%E2%80%9328" target="_blank">Google Scholar</a>]</p>

---

**Disclaimer/Publisher’s Note:** The statements, opinions and data contained in all publications are solely those of the individual author(s) and contributor(s) and not of MDPI and/or the editor(s). MDPI and/or the editor(s) disclaim responsibility for any injury to people or property resulting from any ideas, methods, instructions or products referred to in the content.

© 2024 by the authors. Licensee MDPI, Basel, Switzerland. This article is an open access article distributed under the terms and conditions of the Creative Commons Attribution (CC BY) license ([https://creativecommons.org/licenses/by/4.0/](https://creativecommons.org/licenses/by/4.0/)).

## Share and Cite
      
### MDPI and ACS Style

Yoo, B.; Kim, J.; Park, S.; Ahn, C.R.; Oh, T. Harnessing Generative Pre-Trained Transformers for Construction Accident Prediction with Saliency Visualization. *Appl. Sci.* **2024**, *14*, 664. [https://doi.org/10.3390/app14020664](https://doi.org/10.3390/app14020664)

### AMA Style

Yoo B, Kim J, Park S, Ahn CR, Oh T. Harnessing Generative Pre-Trained Transformers for Construction Accident Prediction with Saliency Visualization. *Applied Sciences*. 2024; 14(2):664. [https://doi.org/10.3390/app14020664](https://doi.org/10.3390/app14020664)

### Chicago/Turabian Style

Yoo, Byunghee, Jinwoo Kim, Seongeun Park, Changbum R. Ahn, and Taekeun Oh. 2024. "Harnessing Generative Pre-Trained Transformers for Construction Accident Prediction with Saliency Visualization" *Applied Sciences* 14, no. 2: 664. [https://doi.org/10.3390/app14020664](https://doi.org/10.3390/app14020664)

<p>Note that from the first issue of 2016, this journal uses article numbers instead of page numbers. See further details <a href="https://www.mdpi.com/about/announcements/784" target="_blank"><b>here</b></a>.</p>{: .notice}